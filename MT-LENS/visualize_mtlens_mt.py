import streamlit as st
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from typing import Dict, List
import numpy as np
import seaborn as sns
from scipy import stats


@st.cache_data
def create_correlation_matrix(sample_scores: List[Dict], selected_metrics: List[str]) -> tuple:
    """åˆ›å»ºç›¸å…³æ€§çŸ©é˜µ"""
    # æå–æ‰€æœ‰æŒ‡æ ‡çš„åˆ†æ•°
    scores_dict = {metric: [] for metric in selected_metrics}
    
    # é¦–å…ˆæ£€æŸ¥æ¯ä¸ªæ ·æœ¬ä¸­æœ‰å“ªäº›æŒ‡æ ‡
    available_metrics = set()
    for score in sample_scores:
        metrics_in_sample = set(score.keys()) & set(selected_metrics)
        available_metrics.update(metrics_in_sample)
    
    # åªä½¿ç”¨æ‰€æœ‰æ ·æœ¬éƒ½æœ‰çš„æŒ‡æ ‡
    common_metrics = [m for m in selected_metrics if m in available_metrics]
    
    # é‡æ–°æ”¶é›†æ•°æ®
    valid_samples = []
    for score in sample_scores:
        # æ£€æŸ¥è¿™ä¸ªæ ·æœ¬æ˜¯å¦åŒ…å«æ‰€æœ‰éœ€è¦çš„æŒ‡æ ‡
        if all(metric in score for metric in common_metrics):
            sample_data = {metric: score[metric] for metric in common_metrics}
            valid_samples.append(sample_data)
    
    # åˆ›å»ºæ•°æ®æ¡†
    if not valid_samples:
        st.warning("æ²¡æœ‰æ‰¾åˆ°åŒ…å«æ‰€æœ‰é€‰å®šæŒ‡æ ‡çš„æ ·æœ¬")
        return None, None
    
    df = pd.DataFrame(valid_samples)
    
    # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
    correlation_matrix = df.corr()
    
    # åˆ›å»ºçƒ­åŠ›å›¾
    fig = go.Figure(data=go.Heatmap(
        z=correlation_matrix,
        x=correlation_matrix.columns,
        y=correlation_matrix.columns,
        text=np.round(correlation_matrix, 3),
        texttemplate='%{text}',
        textfont={"size": 10},
        hoverongaps=False,
        colorscale='RdBu',
        zmid=0
    ))
    
    fig.update_layout(
        title='æŒ‡æ ‡ç›¸å…³æ€§çƒ­åŠ›å›¾',
        width=700,
        height=700
    )
    
    # æ·»åŠ ç¼ºå¤±æŒ‡æ ‡çš„è¯´æ˜
    missing_metrics = set(selected_metrics) - set(common_metrics)
    if missing_metrics:
        st.warning(f"ä»¥ä¸‹æŒ‡æ ‡åœ¨éƒ¨åˆ†æ ·æœ¬ä¸­ç¼ºå¤±ï¼ŒæœªåŒ…å«åœ¨ç›¸å…³æ€§åˆ†æä¸­ï¼š{', '.join(missing_metrics)}")
    
    return fig, correlation_matrix

@st.cache_data
def create_scatter_plot(sample_scores: List[Dict], metric1: str, metric2: str) -> go.Figure:
    """åˆ›å»ºä¸¤ä¸ªæŒ‡æ ‡çš„æ•£ç‚¹å›¾"""
    # æå–ä¸¤ä¸ªæŒ‡æ ‡çš„åˆ†æ•°
    scores = [(score[metric1], score[metric2]) 
             for score in sample_scores 
             if metric1 in score and metric2 in score]
    
    x, y = zip(*scores)
    
    # è®¡ç®—ç›¸å…³ç³»æ•°
    correlation, p_value = stats.pearsonr(x, y)
    
    # åˆ›å»ºæ•£ç‚¹å›¾
    fig = go.Figure(data=go.Scatter(
        x=x,
        y=y,
        mode='markers',
        marker=dict(
            size=8,
            opacity=0.6
        )
    ))
    
    fig.update_layout(
        title=f'{metric1.upper()} vs {metric2.upper()}<br>ç›¸å…³ç³»æ•°: {correlation:.3f} (p-value: {p_value:.3e})',
        xaxis_title=metric1.upper(),
        yaxis_title=metric2.upper(),
        width=600,
        height=400
    )
    
    return fig

@st.cache_data
def load_results(file_path: str) -> Dict:
    """åŠ è½½è¯„ä¼°ç»“æœ"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"åŠ è½½æ•°æ®å¤±è´¥: {str(e)}")
        return None

@st.cache_data
def create_metrics_comparison(corpus_metrics: Dict, selected_metrics: List[str]) -> go.Figure:
    """åˆ›å»ºæŒ‡æ ‡å¯¹æ¯”å›¾"""
    # åªé€‰æ‹©æŒ‡å®šçš„æŒ‡æ ‡
    metrics = {k: v for k, v in corpus_metrics.items() if k in selected_metrics and v is not None}
    
    if not metrics:
        st.warning("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æŒ‡æ ‡æ•°æ®")
        return None

    fig = go.Figure(data=[
        go.Bar(
            x=list(metrics.keys()),
            y=list(metrics.values()),
            text=[f'{v:.2f}' for v in metrics.values()],
            textposition='auto',
        )
    ])
    
    fig.update_layout(
        title='å„è¯„ä¼°æŒ‡æ ‡å¯¹æ¯”',
        xaxis_title='è¯„ä¼°æŒ‡æ ‡',
        yaxis_title='å¾—åˆ†',
        yaxis_range=[0, max(metrics.values()) * 1.1]
    )
    
    return fig

@st.cache_data
def create_score_distribution(sample_scores: List[Dict], metric: str) -> go.Figure:
    """åˆ›å»ºæŒ‡æ ‡åˆ†å¸ƒå›¾"""
    scores = [score[metric] for score in sample_scores if metric in score and score[metric] is not None]

    if not scores:
        st.warning(f"æ²¡æœ‰æ‰¾åˆ° {metric} çš„æœ‰æ•ˆæ•°æ®")
        return None
    
    fig = go.Figure(data=[
        go.Histogram(
            x=scores,
            nbinsx=30,
            name=metric.upper()
        )
    ])
    
    fig.update_layout(
        title=f'{metric.upper()} åˆ†æ•°åˆ†å¸ƒ',
        xaxis_title='åˆ†æ•°',
        yaxis_title='æ ·æœ¬æ•°é‡'
    )
    
    return fig

def main():
    # æŒ‡å®šè¦æ˜¾ç¤ºçš„æŒ‡æ ‡
    SELECTED_METRICS = [
        'bleu',
        'chrf',
        'ter',
        'meteor',
        'rouge1',
        'rouge2',
        'rougeL',
        'comet',
        'bleurt'
    ]
    
    # æŒ‡æ ‡è¯´æ˜
    METRICS_DESCRIPTION = {
        'bleu': 'BLEU score (0-100, è¶Šé«˜è¶Šå¥½)',
        'chrf': 'chrF score (0-100, è¶Šé«˜è¶Šå¥½)',
        'ter': 'Translation Edit Rate (0-100, è¶Šä½è¶Šå¥½)',
        'meteor': 'METEOR score (0-1, è¶Šé«˜è¶Šå¥½)',
        'rouge1': 'ROUGE-1 F1 score (0-1, è¶Šé«˜è¶Šå¥½)',
        'rouge2': 'ROUGE-2 F1 score (0-1, è¶Šé«˜è¶Šå¥½)',
        'rougeL': 'ROUGE-L F1 score (0-1, è¶Šé«˜è¶Šå¥½)',
        'comet': 'COMET segment-level score (0-1, è¶Šé«˜è¶Šå¥½, åŸºäºäººå·¥è¯„åˆ†æ ‡å‡†,wmt22-comet-da)',
        'bleurt': 'BLEURT score (åŸºäºBERTçš„è¯„ä¼°æŒ‡æ ‡, é€šå¸¸åœ¨-1åˆ°1ä¹‹é—´, è¶Šé«˜è¶Šå¥½)'
    }
    
    st.set_page_config(
        page_title="æœºå™¨ç¿»è¯‘è¯„ä¼°ç»“æœåˆ†æ",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("æœºå™¨ç¿»è¯‘è¯„ä¼°ç»“æœåˆ†æ ğŸ“Š")

    # æ·»åŠ æ•°æ®é›†é€‰æ‹©
    datasets = {
        "ä¸­è‹±ç¿»è¯‘": "results/comprehensive_evaluation_resultsZE.json",
        "æ³°è‹±ç¿»è¯‘": "results/comprehensive_evaluation_resultsTE.json",
        "è‹±å°åœ°ç¿»è¯‘": "results/comprehensive_evaluation_resultsEID.json",
        "å°åœ°è‹±ç¿»è¯‘": "results/comprehensive_evaluation_resultsIDE.json",
        "è‹±å°å°¼ç¿»è¯‘": "results/comprehensive_evaluation_resultsEINI.json",
        
    }

    selected_dataset = st.sidebar.selectbox(
        "é€‰æ‹©æ•°æ®é›†",
        list(datasets.keys()),
        format_func=lambda x: x
    )

    results_path = datasets[selected_dataset]
    

    with st.spinner('æ­£åœ¨åŠ è½½æ•°æ®...'):
        results = load_results(results_path)
        
        if results is None:
            st.error(f"æ— æ³•æ‰¾åˆ°æˆ–åŠ è½½ç»“æœæ–‡ä»¶: {results_path}")
            st.stop()
    
    corpus_metrics = results['corpus_metrics']
    sample_scores = results['sample_scores']

    # é¦–å…ˆè®¡ç®—å¯ç”¨æŒ‡æ ‡
    available_metrics = set()
    for score in sample_scores:
        metrics_in_sample = set(score.keys()) & set(SELECTED_METRICS)
        available_metrics.update(metrics_in_sample)
    
    missing_metrics = set(SELECTED_METRICS) - available_metrics
    if missing_metrics:
        st.warning(f"ä»¥ä¸‹æŒ‡æ ‡åœ¨æ•°æ®ä¸­å®Œå…¨ç¼ºå¤±: {', '.join(missing_metrics)}")
    
    partial_metrics = set()
    for metric in available_metrics:
        count = sum(1 for score in sample_scores if metric in score)
        if count < len(sample_scores):
            partial_metrics.add(metric)
    
    if partial_metrics:
        st.warning(f"ä»¥ä¸‹æŒ‡æ ‡åœ¨éƒ¨åˆ†æ ·æœ¬ä¸­ç¼ºå¤±: {', '.join(partial_metrics)}")

    # éœ€è¦å½’ä¸€åŒ–çš„æŒ‡æ ‡åŠå…¶å¤„ç†æ–¹æ³•
    normalize_config = {
        'bleu': {'scale': 100, 'type': 'direct'},  # é™¤ä»¥100
        'chrf': {'scale': 100, 'type': 'direct'},  # é™¤ä»¥100
        'ter': {'scale': 100, 'type': 'inverse'},  # 1 - (å€¼/100)
        'bleurt': {'type': 'minmax'}  # æœ€å°æœ€å¤§å€¼å½’ä¸€åŒ–
    }
    
    # å¯¹corpus_metricsè¿›è¡Œå½’ä¸€åŒ–
    for metric, config in normalize_config.items():
        if metric in corpus_metrics:
            if config['type'] == 'direct':
                corpus_metrics[metric] = corpus_metrics[metric] / config['scale']
            elif config['type'] == 'inverse':
                corpus_metrics[metric] = 1 - (corpus_metrics[metric] / config['scale'])
    
    # å¯¹sample_scoresè¿›è¡Œå½’ä¸€åŒ–
    bleurt_range = None
    if 'bleurt' in available_metrics:
        bleurt_scores = [score['bleurt'] for score in sample_scores if 'bleurt' in score]
        if bleurt_scores:
            bleurt_min = min(bleurt_scores)
            bleurt_max = max(bleurt_scores)
            bleurt_range = bleurt_max - bleurt_min
    
    for score in sample_scores:
        for metric, config in normalize_config.items():
            if metric in score:
                if config['type'] == 'direct':
                    score[metric] = score[metric] / config['scale']
                elif config['type'] == 'inverse':
                    score[metric] = 1 - (score[metric] / config['scale'])
                elif config['type'] == 'minmax' and bleurt_range and bleurt_range > 0:
                    score[metric] = (score[metric] - bleurt_min) / bleurt_range
    
    # æ›´æ–°æŒ‡æ ‡æè¿°
    METRICS_DESCRIPTION.update({
        'bleu': 'BLEU score (0-1, è¶Šé«˜è¶Šå¥½)',
        'chrf': 'chrF score (0-1, è¶Šé«˜è¶Šå¥½)',
        'ter': 'Translation Edit Rate (0-1, è¶Šé«˜è¶Šå¥½)',
        'bleurt': 'BLEURT score (0-1, è¶Šé«˜è¶Šå¥½, å·²å½’ä¸€åŒ–)'
    })


    available_metrics = set()
    for score in sample_scores:
        metrics_in_sample = set(score.keys()) & set(SELECTED_METRICS)
        available_metrics.update(metrics_in_sample)
    
    missing_metrics = set(SELECTED_METRICS) - available_metrics
    if missing_metrics:
        st.warning(f"ä»¥ä¸‹æŒ‡æ ‡åœ¨æ•°æ®ä¸­å®Œå…¨ç¼ºå¤±: {', '.join(missing_metrics)}")
    
    partial_metrics = set()
    for metric in available_metrics:
        count = sum(1 for score in sample_scores if metric in score)
        if count < len(sample_scores):
            partial_metrics.add(metric)
    
    if partial_metrics:
        st.warning(f"ä»¥ä¸‹æŒ‡æ ‡åœ¨éƒ¨åˆ†æ ·æœ¬ä¸­ç¼ºå¤±: {', '.join(partial_metrics)}")
    
    st.sidebar.title("å¯¼èˆª")
    page = st.sidebar.radio(
        "é€‰æ‹©æŸ¥çœ‹å†…å®¹",
        ["æ•´ä½“è¯„ä¼°ç»“æœ", "æŒ‡æ ‡åˆ†å¸ƒåˆ†æ", "æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ", "æ ·æœ¬è¯¦æƒ…"]
    )
    
    if page == "æ•´ä½“è¯„ä¼°ç»“æœ":
        st.header("æ•´ä½“è¯„ä¼°ç»“æœ")
        
        # æ˜¾ç¤ºCOMETç³»ç»Ÿçº§åˆ«å¾—åˆ†
        if 'comet_system' in corpus_metrics:
            col1, col2 = st.columns([1, 2])
            with col1:
                st.metric(
                    "COMET System Score",
                    f"{corpus_metrics['comet_system']:.4f}"
                )
        
        with st.spinner('ç”Ÿæˆå¯¹æ¯”å›¾...'):
            fig = create_metrics_comparison(corpus_metrics, SELECTED_METRICS)
            st.plotly_chart(fig, use_container_width=True)
            
        st.subheader("è¯¦ç»†æŒ‡æ ‡æ•°å€¼")
        metrics_df = pd.DataFrame({
            "æŒ‡æ ‡": [m for m in SELECTED_METRICS if m in corpus_metrics],
            "å¾—åˆ†": [corpus_metrics[m] for m in SELECTED_METRICS if m in corpus_metrics]
        })
        st.dataframe(metrics_df.round(4))
        
    elif page == "æŒ‡æ ‡åˆ†å¸ƒåˆ†æ":
        st.header("æŒ‡æ ‡åˆ†å¸ƒåˆ†æ")
        
        selected_metric = st.selectbox(
            "é€‰æ‹©è¦æŸ¥çœ‹çš„æŒ‡æ ‡",
            SELECTED_METRICS,
            format_func=lambda x: x.upper()
        )
        
        with st.spinner('ç”Ÿæˆåˆ†å¸ƒå›¾...'):
            fig = create_score_distribution(sample_scores, selected_metric)
            st.plotly_chart(fig, use_container_width=True)
            
        scores = [score[selected_metric] for score in sample_scores if selected_metric in score]
        if scores:
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯")
                stats_df = pd.DataFrame({
                    "ç»Ÿè®¡é‡": ["å¹³å‡å€¼", "ä¸­ä½æ•°", "æœ€å¤§å€¼", "æœ€å°å€¼", "æ ‡å‡†å·®"],
                    "å€¼": [
                        np.mean(scores),
                        np.median(scores),
                        np.max(scores),
                        np.min(scores),
                        np.std(scores)
                    ]
                })
                st.dataframe(stats_df.round(4))
            
            with col2:
                st.subheader("åˆ†ä½æ•°ä¿¡æ¯")
                quantiles = np.percentile(scores, [25, 50, 75])
                quantiles_df = pd.DataFrame({
                    "åˆ†ä½æ•°": ["25%", "50%", "75%"],
                    "å€¼": quantiles
                })
                st.dataframe(quantiles_df.round(4))
    
    elif page == "æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ":
        st.header("æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ")
        
        # æ˜¾ç¤ºç›¸å…³æ€§çƒ­åŠ›å›¾
        st.subheader("1. ç›¸å…³æ€§çƒ­åŠ›å›¾")
        with st.spinner('ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾...'):
            result = create_correlation_matrix(sample_scores, SELECTED_METRICS)
            if result is not None:
                corr_fig, corr_matrix = result
                if corr_fig is not None:
                    st.plotly_chart(corr_fig, use_container_width=True)

                    st.info("""
                    æ³¨æ„ï¼šBLEURT åˆ†æ•°çš„èŒƒå›´ä¸å…¶ä»–æŒ‡æ ‡ä¸åŒï¼Œä½†ç›¸å…³æ€§åˆ†æå·²ç»è€ƒè™‘äº†è¿™ä¸€ç‚¹ã€‚
                    ç›¸å…³ç³»æ•°åæ˜ çš„æ˜¯å˜åŒ–è¶‹åŠ¿çš„ä¸€è‡´æ€§ï¼Œè€Œä¸æ˜¯ç»å¯¹å€¼çš„å¤§å°ã€‚
                    """)

                    st.subheader("æŒ‡æ ‡ç›¸å…³æ€§åˆ†ææ‘˜è¦")
                    
                    # è·å–ç›¸å…³ç³»æ•°çŸ©é˜µçš„ä¸Šä¸‰è§’éƒ¨åˆ†ï¼ˆä¸åŒ…æ‹¬å¯¹è§’çº¿ï¼‰
                    upper_triangle = np.triu(corr_matrix, k=1)
                    
                    # æ‰¾å‡ºæœ€ç›¸å…³çš„ä¸¤ä¸ªæŒ‡æ ‡
                    max_corr_idx = np.unravel_index(np.argmax(np.abs(upper_triangle)), upper_triangle.shape)
                    max_corr = upper_triangle[max_corr_idx]
                    metric1, metric2 = corr_matrix.index[max_corr_idx[0]], corr_matrix.columns[max_corr_idx[1]]
                    
                    # æ‰¾å‡ºæœ€ä¸ç›¸å…³çš„ä¸¤ä¸ªæŒ‡æ ‡
                    # å°†0æ›¿æ¢ä¸ºnanä»¥é¿å…é€‰ä¸­æ²¡æœ‰è®¡ç®—ç›¸å…³ç³»æ•°çš„æŒ‡æ ‡å¯¹
                    upper_triangle_no_zeros = np.where(upper_triangle != 0, upper_triangle, np.nan)
                    min_corr_idx = np.unravel_index(np.nanargmin(np.abs(upper_triangle_no_zeros)), upper_triangle.shape)
                    min_corr = upper_triangle[min_corr_idx]
                    metric3, metric4 = corr_matrix.index[min_corr_idx[0]], corr_matrix.columns[min_corr_idx[1]]
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**æœ€ç›¸å…³çš„æŒ‡æ ‡å¯¹ï¼š**")
                        st.markdown(f"**{metric1.upper()}** å’Œ **{metric2.upper()}**")
                        st.markdown(f"ç›¸å…³ç³»æ•°: {max_corr:.3f}")
                        if abs(max_corr) > 0.7:
                            st.markdown("ğŸ‘‰ è¿™ä¸¤ä¸ªæŒ‡æ ‡å…·æœ‰å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼Œå¯èƒ½åœ¨è¯„ä¼°ç›¸ä¼¼çš„ç¿»è¯‘ç‰¹å¾ã€‚")
                    
                    with col2:
                        st.markdown("**æœ€ä¸ç›¸å…³çš„æŒ‡æ ‡å¯¹ï¼š**")
                        st.markdown(f"**{metric3.upper()}** å’Œ **{metric4.upper()}**")
                        st.markdown(f"ç›¸å…³ç³»æ•°: {min_corr:.3f}")
                        st.markdown("ğŸ‘‰ è¿™ä¸¤ä¸ªæŒ‡æ ‡å¯èƒ½åœ¨è¯„ä¼°ä¸åŒçš„ç¿»è¯‘ç‰¹å¾ï¼Œç»„åˆä½¿ç”¨å¯èƒ½æ›´å…¨é¢ã€‚")

                    st.info("""
                    ğŸ’¡ æç¤ºï¼š
                    - é«˜ç›¸å…³æ€§ï¼ˆ>0.7ï¼‰è¡¨ç¤ºä¸¤ä¸ªæŒ‡æ ‡å¯èƒ½åœ¨è¯„ä¼°ç›¸ä¼¼çš„ç¿»è¯‘ç‰¹å¾
                    - ä½ç›¸å…³æ€§ï¼ˆ<0.3ï¼‰è¡¨ç¤ºä¸¤ä¸ªæŒ‡æ ‡å¯èƒ½åœ¨è¯„ä¼°ä¸åŒçš„ç¿»è¯‘ç‰¹å¾
                    - åœ¨å®é™…è¯„ä¼°ä¸­ï¼Œå»ºè®®é€‰æ‹©ç›¸å…³æ€§è¾ƒä½çš„æŒ‡æ ‡ç»„åˆï¼Œä»¥è·å¾—æ›´å…¨é¢çš„è¯„ä¼°
                    """)


        
        # æ˜¾ç¤ºå…·ä½“ä¸¤ä¸ªæŒ‡æ ‡çš„ç›¸å…³æ€§åˆ†æ
        st.subheader("2. æŒ‡æ ‡å¯¹æ¯”åˆ†æ")
        col1, col2 = st.columns(2)
        with col1:
            metric1 = st.selectbox(
                "é€‰æ‹©ç¬¬ä¸€ä¸ªæŒ‡æ ‡",
                SELECTED_METRICS,
                index=0,
                key='metric1'
            )
        with col2:
            metric2 = st.selectbox(
                "é€‰æ‹©ç¬¬äºŒä¸ªæŒ‡æ ‡",
                SELECTED_METRICS,
                index=1,
                key='metric2'
            )
        
        if metric1 != metric2:
            with st.spinner('ç”Ÿæˆæ•£ç‚¹å›¾...'):
                scatter_fig = create_scatter_plot(sample_scores, metric1, metric2)
                st.plotly_chart(scatter_fig, use_container_width=True)
                
                # æ˜¾ç¤ºç›¸å…³æ€§è§£é‡Š
                correlation = corr_matrix.loc[metric1, metric2]
                st.write("### ç›¸å…³æ€§è§£é‡Š")
                if abs(correlation) > 0.7:
                    strength = "å¼º"
                elif abs(correlation) > 0.3:
                    strength = "ä¸­ç­‰"
                else:
                    strength = "å¼±"
                    
                direction = "æ­£" if correlation > 0 else "è´Ÿ"
                st.write(f"è¿™ä¸¤ä¸ªæŒ‡æ ‡ä¹‹é—´å­˜åœ¨{strength}çš„{direction}ç›¸å…³æ€§ (ç›¸å…³ç³»æ•°: {correlation:.3f})")
        else:
            st.warning("è¯·é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„æŒ‡æ ‡è¿›è¡Œå¯¹æ¯”")    
    else:  # æ ·æœ¬è¯¦æƒ…
        st.header("æ ·æœ¬è¯¦æƒ…æŸ¥çœ‹")
        
        sample_index = st.number_input(
            "è¾“å…¥æ ·æœ¬åºå·",
            min_value=1,
            max_value=len(sample_scores),
            value=1
        ) - 1
        
        sample = sample_scores[sample_index]
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**æºæ–‡æœ¬:**")
            st.write(sample['source'])
        with col2:
            st.markdown("**å‚è€ƒè¯‘æ–‡:**")
            st.write(sample['reference'])
        
        st.markdown("**æ¨¡å‹è¯‘æ–‡:**")
        st.write(sample['hypothesis'])
        
        st.markdown("**è¯„åˆ†è¯¦æƒ…:**")
        metrics = {k: v for k, v in sample.items() if k in SELECTED_METRICS}
        metrics_df = pd.DataFrame(metrics.items(), columns=['æŒ‡æ ‡', 'å¾—åˆ†'])
        st.dataframe(metrics_df.round(4))
    
    # æ·»åŠ æŒ‡æ ‡è¯´æ˜
    with st.sidebar.expander("æŒ‡æ ‡è¯´æ˜"):
        for metric in SELECTED_METRICS:
            if metric in METRICS_DESCRIPTION:
                st.markdown(f"**{metric.upper()}**: {METRICS_DESCRIPTION[metric]}")

if __name__ == "__main__":
    main() 