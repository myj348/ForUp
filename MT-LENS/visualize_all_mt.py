import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import os
import numpy as np
from scipy import stats

def load_data():
    """åŠ è½½æ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†"""
    file_path = 'data/æœºå™¨ç¿»è¯‘æ•ˆæœè¯„ä¼°.xlsx'
    
    sheet_names = {
        'Chn2Eng': 'Chn2Eng',
        'Thai2Eng': 'Thai2Eng',
        'Eng2Indi': 'Eng2Indi',
        'Indi2Eng': 'Indi2Eng',
        'Eng2Indo': 'Eng2Indo'
    }
    
    data_dict = {}
    for key, sheet_name in sheet_names.items():
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        df['åºå·'] = range(1, len(df) + 1)
        data_dict[key] = df
    
    return data_dict

def analyze_metrics_consistency(df, selected_metrics):
    """åˆ†ææŒ‡æ ‡ä¸ Gemini2.0 Score çš„ä¸€è‡´æ€§"""
    if 'Gemini2.0 Score' not in df.columns:
        return None
    
    gemini_scores = df['Gemini2.0 Score']
    consistency_results = []
    
    for metric in selected_metrics:
        if metric != 'Gemini2.0 Score' and metric in df.columns:
            correlation, _ = stats.pearsonr(gemini_scores, df[metric])
            consistency_results.append({
                'metric': metric,
                'correlation': abs(correlation),
                'original_correlation': correlation
            })
    
    # æŒ‰ç›¸å…³æ€§ç»å¯¹å€¼æ’åº
    consistency_results.sort(key=lambda x: x['correlation'], reverse=True)
    
    if consistency_results:
        most_consistent = consistency_results[0]
        least_consistent = consistency_results[-1]
        return most_consistent, least_consistent
    return None

def plot_metrics(df, selected_metrics):
    """ç»˜åˆ¶æŒ‡æ ‡æŠ˜çº¿å›¾"""
    fig = go.Figure()
    
    # å§‹ç»ˆæ·»åŠ  Gemini2.0 Score
    if 'Gemini2.0 Score' in df.columns:
        fig.add_trace(go.Scatter(
            x=df['åºå·'],
            y=df['Gemini2.0 Score'],
            name='Gemini2.0 Score',
            line=dict(width=3)
        ))
    
    # æ·»åŠ é€‰ä¸­çš„å…¶ä»–æŒ‡æ ‡
    for metric in selected_metrics:
        if metric in df.columns and metric != 'Gemini2.0 Score':
            fig.add_trace(go.Scatter(
                x=df['åºå·'],
                y=df[metric],
                name=metric,
                line=dict(width=1)
            ))
    
    fig.update_layout(
        title='ç¿»è¯‘è¯„ä¼°æŒ‡æ ‡å¯¹æ¯”',
        xaxis_title='åºå·',
        yaxis_title='åˆ†æ•°',
        hovermode='x unified',
        height=600,
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="left",
            x=1.02
        )
    )
    
    return fig


def calculate_statistics(df, selected_metrics):
    """è®¡ç®—åŸºæœ¬ç»Ÿè®¡é‡"""
    stats_results = {}
    
    for metric in selected_metrics:
        if metric in df.columns:
            values = df[metric].values
            stats_results[metric] = {
                'å‡å€¼': np.mean(values),
                'ä¸­ä½æ•°': np.median(values),
                'æ ‡å‡†å·®': np.std(values),
                'æ–¹å·®': np.var(values),
                'æå·®': np.ptp(values),
                '25%åˆ†ä½æ•°': np.percentile(values, 25),
                '75%åˆ†ä½æ•°': np.percentile(values, 75),
                'æœ€å°å€¼': np.min(values),
                'æœ€å¤§å€¼': np.max(values)
            }
    
    return stats_results

def analyze_threshold(df, selected_metrics, threshold=0.8):
    """é˜ˆå€¼åˆ†æ"""
    threshold_results = {}
    
    for metric in selected_metrics:
        if metric in df.columns:
            values = df[metric].values
            above_threshold = np.sum(values >= threshold)
            threshold_results[metric] = {
                'é«˜äºé˜ˆå€¼çš„æ•°é‡': above_threshold,
                'é«˜äºé˜ˆå€¼çš„æ¯”ä¾‹': above_threshold / len(values)
            }
    
    return threshold_results

def analyze_quartiles(df, selected_metrics):
    """åˆ†ä½æ•°åˆ†ç»„åˆ†æ"""
    quartile_results = {}
    
    for metric in selected_metrics:
        if metric in df.columns:
            values = df[metric].values
            q1, q2, q3 = np.percentile(values, [25, 50, 75])
            quartile_results[metric] = {
                'é«˜åˆ†ç»„(å‰25%)': np.sum(values > q3),
                'ä¸­åˆ†ç»„(25%-75%)': np.sum((values >= q1) & (values <= q3)),
                'ä½åˆ†ç»„(å25%)': np.sum(values < q1),
                'å„ç»„å æ¯”': {
                    'é«˜åˆ†ç»„': np.sum(values > q3) / len(values),
                    'ä¸­åˆ†ç»„': np.sum((values >= q1) & (values <= q3)) / len(values),
                    'ä½åˆ†ç»„': np.sum(values < q1) / len(values)
                }
            }
    
    return quartile_results




def main():
    st.set_page_config(layout="wide")
    st.title('æœºå™¨ç¿»è¯‘è¯„ä¼°å¯è§†åŒ–')
    
    try:
        # åŠ è½½æ•°æ®
        data_dict = load_data()
        
        # æ•°æ®é›†é€‰æ‹©
        dataset = st.selectbox(
            'é€‰æ‹©æ•°æ®é›†',
            list(data_dict.keys()),
            format_func=lambda x: f"{x} æ•°æ®é›†"
        )
        
        # è·å–é€‰ä¸­çš„æ•°æ®é›†
        df = data_dict[dataset]
        
        # å®šä¹‰æ‰€æœ‰å¯é€‰çš„æŒ‡æ ‡
        all_metrics = [
            'MT-IENS BLEU', 'MT-IENS TRE', 'MT-IENS CHRF', 
            'MT-IENS COMET', 'MT-IENS BLEURT', 'MT-IENS METEOR', 
            'ChatGPT error stat', 'BLEU','Prompt Template', 'xComet'
        ]
        
        # åˆ›å»ºæŒ‡æ ‡é€‰æ‹©çš„å¤šé€‰æ¡†
        col1, col2 = st.columns([3, 1])
        with col2:
            st.write("é€‰æ‹©è¦æ˜¾ç¤ºçš„æŒ‡æ ‡ï¼š")
            selected_metrics = ['Gemini2.0 Score']  # é»˜è®¤å§‹ç»ˆåŒ…å«
            for metric in all_metrics:
                if metric in df.columns:
                    if st.checkbox(metric, value=False):
                        selected_metrics.append(metric)
            
            # æ˜¾ç¤ºä¸€è‡´æ€§åˆ†æç»“æœ
            if len(selected_metrics) > 2:  # è‡³å°‘éœ€è¦ä¸¤ä¸ªå…¶ä»–æŒ‡æ ‡æ‰èƒ½æ¯”è¾ƒ
                st.write("---")
                st.write("æŒ‡æ ‡ä¸€è‡´æ€§åˆ†æï¼š")
                
                consistency_result = analyze_metrics_consistency(df, selected_metrics)
                if consistency_result:
                    most_consistent, least_consistent = consistency_result
                    
                    st.write("æœ€ä¸€è‡´çš„æŒ‡æ ‡ï¼š")
                    st.write(f"ğŸ“ˆ {most_consistent['metric']} (ç›¸å…³ç³»æ•°: {most_consistent['original_correlation']:.3f})")
                    
                    st.write("æœ€ä¸ä¸€è‡´çš„æŒ‡æ ‡ï¼š")
                    st.write(f"ğŸ“‰ {least_consistent['metric']} (ç›¸å…³ç³»æ•°: {least_consistent['original_correlation']:.3f})")
        
        
        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡é‡
            if len(selected_metrics) > 0:
                st.write("---")
                st.write("åŸºæœ¬ç»Ÿè®¡åˆ†æï¼š")
                stats_results = calculate_statistics(df, selected_metrics)
                for metric, stats in stats_results.items():
                    st.write(f"**{metric}**")
                    for stat_name, value in stats.items():
                        st.write(f"{stat_name}: {value:.4f}")
                
                # æ˜¾ç¤ºé˜ˆå€¼åˆ†æ
                st.write("---")
                st.write("é˜ˆå€¼åˆ†æ (é˜ˆå€¼=0.8)ï¼š")
                threshold_results = analyze_threshold(df, selected_metrics)
                for metric, results in threshold_results.items():
                    st.write(f"**{metric}**")
                    st.write(f"é«˜äºé˜ˆå€¼çš„æ•°é‡: {results['é«˜äºé˜ˆå€¼çš„æ•°é‡']}")
                    st.write(f"é«˜äºé˜ˆå€¼çš„æ¯”ä¾‹: {results['é«˜äºé˜ˆå€¼çš„æ¯”ä¾‹']:.2%}")
                
                # æ˜¾ç¤ºåˆ†ä½æ•°åˆ†ç»„åˆ†æ
                st.write("---")
                st.write("åˆ†ä½æ•°åˆ†ç»„åˆ†æï¼š")
                quartile_results = analyze_quartiles(df, selected_metrics)
                for metric, results in quartile_results.items():
                    st.write(f"**{metric}**")
                    st.write("åˆ†ç»„æ•°é‡ï¼š")
                    st.write(f"é«˜åˆ†ç»„: {results['é«˜åˆ†ç»„(å‰25%)']}")
                    st.write(f"ä¸­åˆ†ç»„: {results['ä¸­åˆ†ç»„(25%-75%)']}")
                    st.write(f"ä½åˆ†ç»„: {results['ä½åˆ†ç»„(å25%)']}")
                    
                    # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå„ç»„å æ¯”
                    st.write("å„ç»„å æ¯”ï¼š")
                    st.progress(results['å„ç»„å æ¯”']['é«˜åˆ†ç»„'])
                    st.write(f"é«˜åˆ†ç»„: {results['å„ç»„å æ¯”']['é«˜åˆ†ç»„']:.2%}")
                    st.progress(results['å„ç»„å æ¯”']['ä¸­åˆ†ç»„'])
                    st.write(f"ä¸­åˆ†ç»„: {results['å„ç»„å æ¯”']['ä¸­åˆ†ç»„']:.2%}")
                    st.progress(results['å„ç»„å æ¯”']['ä½åˆ†ç»„'])
                    st.write(f"ä½åˆ†ç»„: {results['å„ç»„å æ¯”']['ä½åˆ†ç»„']:.2%}")
        
        # åœ¨ä¸»åˆ—ä¸­æ˜¾ç¤ºå›¾è¡¨
        with col1:
            st.plotly_chart(plot_metrics(df, selected_metrics), use_container_width=True)
        
        # æ·»åŠ åºå·é€‰æ‹©å™¨å’Œå¯¹åº”çš„æ–‡æœ¬æ˜¾ç¤º
        selected_index = st.selectbox('é€‰æ‹©åºå·æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯', df['åºå·'])
        
        # æ˜¾ç¤ºé€‰ä¸­åºå·çš„æºæ–‡æœ¬å’Œç¿»è¯‘ç»“æœ
        selected_row = df[df['åºå·'] == selected_index].iloc[0]
        st.subheader('è¯¦ç»†ä¿¡æ¯')
        text_col1, text_col2 = st.columns(2)
        with text_col1:
            st.text_area('Test Case Source Language', selected_row['Test Case Source Language'], height=150)
        with text_col2:
            st.text_area('Machine Translate Result', selected_row['Machine Translate Result'], height=150)
            
    except Exception as e:
        st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
        st.write("é”™è¯¯è¯¦æƒ…:", e)

if __name__ == '__main__':
    main() 